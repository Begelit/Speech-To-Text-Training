{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-31T12:49:15.214565Z","iopub.execute_input":"2023-01-31T12:49:15.215010Z","iopub.status.idle":"2023-01-31T12:49:15.375628Z","shell.execute_reply.started":"2023-01-31T12:49:15.214932Z","shell.execute_reply":"2023-01-31T12:49:15.374654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imports and installations","metadata":{}},{"cell_type":"code","source":"#!pip install datasets>=1.18.3\n!pip install transformers==4.11.3\n!pip install librosa\n!pip install jiwer","metadata":{"execution":{"iopub.status.busy":"2023-01-31T12:49:15.377510Z","iopub.execute_input":"2023-01-31T12:49:15.378084Z","iopub.status.idle":"2023-01-31T12:49:56.520214Z","shell.execute_reply.started":"2023-01-31T12:49:15.378049Z","shell.execute_reply":"2023-01-31T12:49:56.518997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset, load_metric, Audio\nimport os\nimport torch\n\n#set_caching_enabled(False)\n\nminds = load_dataset(\"superb\",\"asr\", split=\"train\")\nminds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))\nminds = minds.remove_columns(['speaker_id', 'chapter_id', 'id'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nchars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"]' #ignore some special characters\n\ndef remove_special_characters(batch):\n    batch[\"text\"] = re.sub(chars_to_ignore_regex, '', batch[\"text\"]).lower()\n    return batch\n\nminds = minds.map(remove_special_characters)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T12:58:33.283532Z","iopub.execute_input":"2023-01-31T12:58:33.283892Z","iopub.status.idle":"2023-01-31T12:58:36.450394Z","shell.execute_reply.started":"2023-01-31T12:58:33.283862Z","shell.execute_reply":"2023-01-31T12:58:36.449490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"minds = minds.train_test_split(test_size=0.2) #split data into train and test\nminds[\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2023-01-31T12:58:47.568132Z","iopub.execute_input":"2023-01-31T12:58:47.568864Z","iopub.status.idle":"2023-01-31T12:58:52.063005Z","shell.execute_reply.started":"2023-01-31T12:58:47.568825Z","shell.execute_reply":"2023-01-31T12:58:52.061323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_all_chars(batch):\n    all_text = \" \".join(batch[\"text\"])\n    vocab = list(set(all_text))\n    return {\"vocab\": [vocab], \"all_text\": [all_text]}\nvocabs = minds.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=minds.column_names[\"train\"])","metadata":{"execution":{"iopub.status.busy":"2023-01-31T12:58:56.289428Z","iopub.execute_input":"2023-01-31T12:58:56.289803Z","iopub.status.idle":"2023-01-31T12:58:57.127361Z","shell.execute_reply.started":"2023-01-31T12:58:56.289771Z","shell.execute_reply":"2023-01-31T12:58:57.126269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_list = list(set(vocabs[\"train\"][\"vocab\"][0]) | set(vocabs[\"test\"][\"vocab\"][0]))\nvocab_dict = {v: k for k, v in enumerate(vocab_list)}\nvocab_dict","metadata":{"execution":{"iopub.status.busy":"2023-01-31T12:59:16.568779Z","iopub.execute_input":"2023-01-31T12:59:16.569191Z","iopub.status.idle":"2023-01-31T12:59:16.579531Z","shell.execute_reply.started":"2023-01-31T12:59:16.569158Z","shell.execute_reply":"2023-01-31T12:59:16.578316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_dict[\"|\"] = vocab_dict[\" \"]\ndel vocab_dict[\" \"]\nvocab_dict[\"[UNK]\"] = len(vocab_dict) #UNK for unknown\nvocab_dict[\"[PAD]\"] = len(vocab_dict) #PAD for padding sequences\nprint(len(vocab_dict))","metadata":{"execution":{"iopub.status.busy":"2023-01-31T12:59:20.213837Z","iopub.execute_input":"2023-01-31T12:59:20.214184Z","iopub.status.idle":"2023-01-31T12:59:20.220161Z","shell.execute_reply.started":"2023-01-31T12:59:20.214156Z","shell.execute_reply":"2023-01-31T12:59:20.219043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nwith open('./vocab.json', 'w') as vocab_file:\n    json.dump(vocab_dict, vocab_file)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T12:59:23.609932Z","iopub.execute_input":"2023-01-31T12:59:23.610331Z","iopub.status.idle":"2023-01-31T12:59:23.615894Z","shell.execute_reply.started":"2023-01-31T12:59:23.610295Z","shell.execute_reply":"2023-01-31T12:59:23.614791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training model","metadata":{}},{"cell_type":"code","source":"from transformers import Wav2Vec2CTCTokenizer\n\ntokenizer = Wav2Vec2CTCTokenizer(\"./vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")","metadata":{"execution":{"iopub.status.busy":"2023-01-31T12:59:26.864917Z","iopub.execute_input":"2023-01-31T12:59:26.865267Z","iopub.status.idle":"2023-01-31T12:59:36.522599Z","shell.execute_reply.started":"2023-01-31T12:59:26.865237Z","shell.execute_reply":"2023-01-31T12:59:36.521515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir(\"./tokenizer_dir\")\n\ntokenizer.save_pretrained(\"./tokenizer_dir\")","metadata":{"execution":{"iopub.status.busy":"2023-01-31T12:59:36.524641Z","iopub.execute_input":"2023-01-31T12:59:36.525233Z","iopub.status.idle":"2023-01-31T12:59:36.535144Z","shell.execute_reply.started":"2023-01-31T12:59:36.525186Z","shell.execute_reply":"2023-01-31T12:59:36.532063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Wav2Vec2FeatureExtractor\n\nfeature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T12:59:47.837664Z","iopub.execute_input":"2023-01-31T12:59:47.838040Z","iopub.status.idle":"2023-01-31T12:59:47.847768Z","shell.execute_reply.started":"2023-01-31T12:59:47.838011Z","shell.execute_reply":"2023-01-31T12:59:47.846825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Wav2Vec2Processor\n\nprocessor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T12:59:51.103511Z","iopub.execute_input":"2023-01-31T12:59:51.103864Z","iopub.status.idle":"2023-01-31T12:59:51.110509Z","shell.execute_reply.started":"2023-01-31T12:59:51.103835Z","shell.execute_reply":"2023-01-31T12:59:51.109294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset(batch):\n    audio = batch[\"audio\"]\n\n    # batched output is \"un-batched\" to ensure mapping is correct\n    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n    \n    with processor.as_target_processor():\n        batch[\"labels\"] = processor(batch[\"text\"]).input_ids\n    return batch\n","metadata":{"execution":{"iopub.status.busy":"2023-01-31T12:59:55.961786Z","iopub.execute_input":"2023-01-31T12:59:55.962147Z","iopub.status.idle":"2023-01-31T12:59:55.968122Z","shell.execute_reply.started":"2023-01-31T12:59:55.962116Z","shell.execute_reply":"2023-01-31T12:59:55.967073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"minds = minds.map(prepare_dataset, remove_columns=minds.column_names[\"train\"], num_proc=2)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T13:07:14.843781Z","iopub.execute_input":"2023-01-31T13:07:14.844155Z","iopub.status.idle":"2023-01-31T13:11:52.850407Z","shell.execute_reply.started":"2023-01-31T13:07:14.844126Z","shell.execute_reply":"2023-01-31T13:11:52.848440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass, field\nfrom typing import Any, Dict, List, Optional, Union\n\n@dataclass\nclass DataCollatorCTCWithPadding:\n    \"\"\"\n    Data collator that will dynamically pad the inputs received.\n    Args:\n        processor (:class:`~transformers.Wav2Vec2Processor`)\n            The processor used for proccessing the data.\n        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n            among:\n            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n              sequence if provided).\n            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n              maximum acceptable input length for the model if that argument is not provided.\n            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n              different lengths).\n        max_length (:obj:`int`, `optional`):\n            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n        max_length_labels (:obj:`int`, `optional`):\n            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n        pad_to_multiple_of (:obj:`int`, `optional`):\n            If set will pad the sequence to a multiple of the provided value.\n            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n            7.5 (Volta).\n    \"\"\"\n\n    processor: Wav2Vec2Processor\n    padding: Union[bool, str] = True\n    max_length: Optional[int] = None\n    max_length_labels: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    pad_to_multiple_of_labels: Optional[int] = None\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lengths and need\n        # different padding methods\n        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n\n        batch = self.processor.pad(\n            input_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors=\"pt\",\n        )\n        with self.processor.as_target_processor():\n            labels_batch = self.processor.pad(\n                label_features,\n                padding=self.padding,\n                max_length=self.max_length_labels,\n                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n                return_tensors=\"pt\",\n            )\n\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        batch[\"labels\"] = labels\n\n        return batch\n","metadata":{"execution":{"iopub.status.busy":"2023-01-31T13:11:55.708862Z","iopub.execute_input":"2023-01-31T13:11:55.709253Z","iopub.status.idle":"2023-01-31T13:11:55.724594Z","shell.execute_reply.started":"2023-01-31T13:11:55.709218Z","shell.execute_reply":"2023-01-31T13:11:55.723406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T13:12:05.517766Z","iopub.execute_input":"2023-01-31T13:12:05.518179Z","iopub.status.idle":"2023-01-31T13:12:05.523579Z","shell.execute_reply.started":"2023-01-31T13:12:05.518145Z","shell.execute_reply":"2023-01-31T13:12:05.522469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wer_metric = load_metric(\"wer\")","metadata":{"execution":{"iopub.status.busy":"2023-01-31T13:12:08.488868Z","iopub.execute_input":"2023-01-31T13:12:08.489259Z","iopub.status.idle":"2023-01-31T13:12:09.232207Z","shell.execute_reply.started":"2023-01-31T13:12:08.489221Z","shell.execute_reply":"2023-01-31T13:12:09.231300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef compute_metrics(pred):\n    pred_logits = pred.predictions\n    pred_ids = np.argmax(pred_logits, axis=-1)\n\n    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n\n    pred_str = processor.batch_decode(pred_ids)\n    # we do not want to group tokens when computing the metrics\n    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n\n    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n    #print({\"wer\": wer})\n    return {\"wer\": wer}\n","metadata":{"execution":{"iopub.status.busy":"2023-01-31T13:12:12.824561Z","iopub.execute_input":"2023-01-31T13:12:12.825003Z","iopub.status.idle":"2023-01-31T13:12:12.834852Z","shell.execute_reply.started":"2023-01-31T13:12:12.824965Z","shell.execute_reply":"2023-01-31T13:12:12.833341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Wav2Vec2ForCTC\n\n#model = Wav2Vec2ForCTC.from_pretrained(\n#    \"/kaggle/input/stt-readymade-checkpoint/checkpoint-4000\", \n#    ctc_loss_reduction=\"mean\", \n#    pad_token_id=processor.tokenizer.pad_token_id,\n#)\n\n#Models can also be provided instead of checkpoints\n\nmodel = Wav2Vec2ForCTC.from_pretrained(\n    \"/kaggle/input/stt-full-data-v5/checkpoint-9800\", #loading checkpoint\n    ctc_loss_reduction=\"mean\", \n    pad_token_id=processor.tokenizer.pad_token_id,\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-01-31T13:15:59.154776Z","iopub.execute_input":"2023-01-31T13:15:59.155248Z","iopub.status.idle":"2023-01-31T13:16:15.505622Z","shell.execute_reply.started":"2023-01-31T13:15:59.155209Z","shell.execute_reply":"2023-01-31T13:16:15.504337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.freeze_feature_extractor()","metadata":{"execution":{"iopub.status.busy":"2023-01-31T13:16:15.510779Z","iopub.execute_input":"2023-01-31T13:16:15.513775Z","iopub.status.idle":"2023-01-31T13:16:15.520810Z","shell.execute_reply.started":"2023-01-31T13:16:15.513730Z","shell.execute_reply":"2023-01-31T13:16:15.519562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.mkdir(\"./model\")","metadata":{"execution":{"iopub.status.busy":"2023-01-31T13:16:20.068505Z","iopub.execute_input":"2023-01-31T13:16:20.068904Z","iopub.status.idle":"2023-01-31T13:16:20.074155Z","shell.execute_reply.started":"2023-01-31T13:16:20.068871Z","shell.execute_reply":"2023-01-31T13:16:20.072753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\n#Training args can be changed as required.\n\ntraining_args = TrainingArguments(\n  output_dir=\"./model\",\n  group_by_length=True,\n  per_device_train_batch_size=8,\n  evaluation_strategy=\"steps\",\n  num_train_epochs=8,\n  fp16=True,\n  gradient_checkpointing=True,\n  resume_from_checkpoint=\"/kaggle/input/stt-full-data-v5/checkpoint-9800\",\n  save_steps=200,\n  eval_steps=500,\n  logging_steps=50,\n  learning_rate=1e-4,\n  weight_decay=0.005,\n  warmup_steps=1000,\n  save_total_limit=2,\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T13:16:35.124992Z","iopub.execute_input":"2023-01-31T13:16:35.125405Z","iopub.status.idle":"2023-01-31T13:16:35.277860Z","shell.execute_reply.started":"2023-01-31T13:16:35.125372Z","shell.execute_reply":"2023-01-31T13:16:35.276868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer, TrainerCallback\n\n#class PrinterCallback(TrainerCallback):\n#    def on_log(self, args, state, control, logs=None, **kwargs):\n#        _ = logs.pop(\"total_flos\", None)\n#        if state.is_local_process_zero:\n#            print(logs)\n\ntrainer = Trainer(\n    model=model,\n    data_collator=data_collator,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=minds[\"train\"],\n    eval_dataset=minds[\"test\"],\n    tokenizer=processor.feature_extractor,\n    #callbacks=[PrinterCallback]\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T13:16:41.469726Z","iopub.execute_input":"2023-01-31T13:16:41.470098Z","iopub.status.idle":"2023-01-31T13:16:49.186358Z","shell.execute_reply.started":"2023-01-31T13:16:41.470067Z","shell.execute_reply":"2023-01-31T13:16:49.185247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train(resume_from_checkpoint=\"/kaggle/input/stt-full-data-v5/checkpoint-9800\") #checkpoint needs to be provided to continue training\n#trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-01-31T12:57:04.906588Z","iopub.status.idle":"2023-01-31T12:57:04.907076Z","shell.execute_reply.started":"2023-01-31T12:57:04.906822Z","shell.execute_reply":"2023-01-31T12:57:04.906846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCTC, Wav2Vec2Processor\n\n#Loading models\nmodel = AutoModelForCTC.from_pretrained(\"/kaggle/input/stt-full-data-test-model/model\")\nprocessor = Wav2Vec2Processor.from_pretrained(\"/kaggle/input/stt-full-data-test-model/model\")","metadata":{"execution":{"iopub.status.busy":"2023-02-03T18:35:23.028136Z","iopub.execute_input":"2023-02-03T18:35:23.028942Z","iopub.status.idle":"2023-02-03T18:35:32.138141Z","shell.execute_reply.started":"2023-02-03T18:35:23.028902Z","shell.execute_reply":"2023-02-03T18:35:32.136775Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset, load_metric, Audio\n\nminds = load_dataset(\"PolyAI/minds14\",name=\"en-US\", split=\"train[:100]\")","metadata":{"execution":{"iopub.status.busy":"2023-02-03T18:35:32.144066Z","iopub.execute_input":"2023-02-03T18:35:32.144843Z","iopub.status.idle":"2023-02-03T18:36:08.942179Z","shell.execute_reply.started":"2023-02-03T18:35:32.144790Z","shell.execute_reply":"2023-02-03T18:36:08.940761Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.95k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6dc53b6d48d42678f29f7cd4e6e9921"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset minds14/en-US to /root/.cache/huggingface/datasets/PolyAI___minds14/en-US/1.0.0/aa40414f15e0f919231d617440192034af844835dc1e6a697f4b552e0551fd26...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/471M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02f38b29af1e4bc4a03be65593c3a624"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset minds14 downloaded and prepared to /root/.cache/huggingface/datasets/PolyAI___minds14/en-US/1.0.0/aa40414f15e0f919231d617440192034af844835dc1e6a697f4b552e0551fd26. Subsequent calls will reuse this data.\n","output_type":"stream"}]},{"cell_type":"code","source":"minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))\nminds[8]","metadata":{"execution":{"iopub.status.busy":"2023-02-03T18:38:49.379366Z","iopub.execute_input":"2023-02-03T18:38:49.379774Z","iopub.status.idle":"2023-02-03T18:38:49.490276Z","shell.execute_reply.started":"2023-02-03T18:38:49.379741Z","shell.execute_reply":"2023-02-03T18:38:49.489162Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602baa0fbb1e6d0fbce9214f.wav',\n 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602baa0fbb1e6d0fbce9214f.wav',\n  'array': array([-3.8957143e-05, -2.0281275e-04, -2.0516709e-04, ...,\n         -1.2579626e-02, -1.1464247e-02, -6.2970519e-03], dtype=float32),\n  'sampling_rate': 16000},\n 'transcription': 'I need to find out if I probably set up a joint account',\n 'english_transcription': 'I need to find out if I probably set up a joint account',\n 'intent_class': 11,\n 'lang_id': 4}"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nmind_val = minds[8]\nmind_tens = torch.tensor(mind_val[\"audio\"][\"array\"])\nmind_val","metadata":{"execution":{"iopub.status.busy":"2023-02-03T18:38:52.836919Z","iopub.execute_input":"2023-02-03T18:38:52.837355Z","iopub.status.idle":"2023-02-03T18:38:52.936964Z","shell.execute_reply.started":"2023-02-03T18:38:52.837321Z","shell.execute_reply":"2023-02-03T18:38:52.935584Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602baa0fbb1e6d0fbce9214f.wav',\n 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602baa0fbb1e6d0fbce9214f.wav',\n  'array': array([-3.8957143e-05, -2.0281275e-04, -2.0516709e-04, ...,\n         -1.2579626e-02, -1.1464247e-02, -6.2970519e-03], dtype=float32),\n  'sampling_rate': 16000},\n 'transcription': 'I need to find out if I probably set up a joint account',\n 'english_transcription': 'I need to find out if I probably set up a joint account',\n 'intent_class': 11,\n 'lang_id': 4}"},"metadata":{}}]},{"cell_type":"code","source":"mind_tens_unsq = mind_tens.unsqueeze(0)\nmind_tens_unsq.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-03T18:38:58.374749Z","iopub.execute_input":"2023-02-03T18:38:58.375174Z","iopub.status.idle":"2023-02-03T18:38:58.384120Z","shell.execute_reply.started":"2023-02-03T18:38:58.375138Z","shell.execute_reply":"2023-02-03T18:38:58.382677Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 117400])"},"metadata":{}}]},{"cell_type":"markdown","source":"### Testing on custom audio\nThe cell below was created only for testing purpose on direct audio files. It consists of resampling the input voice and apply MFCC. Moreover, even though we get 2 channels as input, we only require a single channels for predictions and hence, 1 channel is discarded.","metadata":{}},{"cell_type":"code","source":"#import torch\n#import torchaudio\n#import torch.nn as nn\n\n#PATH = \"/kaggle/input/audio-1235/Recording_4.wav\"\n\n#Load audio as waveform\n#waveform, sample_rate = torchaudio.load(PATH)\n\n#Resampling\n#new_sample_rate = 16000\n#transform = nn.Sequential(\n#    torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sample_rate),\n#    torchaudio.transforms.MFCC(sample_rate=new_sample_rate, n_mfcc=64)\n#    )\n\n#channel=0\n#mind_tens_unsq = transform(waveform[channel, :].view(1, -1))","metadata":{"execution":{"iopub.status.busy":"2023-02-03T18:20:30.931904Z","iopub.execute_input":"2023-02-03T18:20:30.932294Z","iopub.status.idle":"2023-02-03T18:20:31.007408Z","shell.execute_reply.started":"2023-02-03T18:20:30.932259Z","shell.execute_reply":"2023-02-03T18:20:31.006397Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    logits = model(mind_tens_unsq).logits\n    pred_ids = torch.argmax(logits, dim=-1)\n    decode_result = processor.batch_decode(pred_ids)[0].replace(\"[PAD]\",'') #Replace PAD token with spaces","metadata":{"execution":{"iopub.status.busy":"2023-02-03T18:39:03.113885Z","iopub.execute_input":"2023-02-03T18:39:03.114323Z","iopub.status.idle":"2023-02-03T18:39:04.798826Z","shell.execute_reply.started":"2023-02-03T18:39:03.114278Z","shell.execute_reply":"2023-02-03T18:39:04.797688Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Example outputs\nAs observable, it works more on the basis of pronunciations and accents. Hence, the results are not perfect but certainly good considering that this is an unseen dataset.","metadata":{}},{"cell_type":"code","source":"print(\"Expected result: \\n\")\nprint(mind_val[\"transcription\"], \"\\n\")\nprint(\"Predicted result: \\n\")\nprint(decode_result,\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-02-03T18:39:05.658134Z","iopub.execute_input":"2023-02-03T18:39:05.658791Z","iopub.status.idle":"2023-02-03T18:39:05.665573Z","shell.execute_reply.started":"2023-02-03T18:39:05.658753Z","shell.execute_reply":"2023-02-03T18:39:05.664308Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Expected result: \n\nI need to find out if I probably set up a joint account \n\nPredicted result: \n\nha i need to find out about how to set up a jointo kan please \n\n","output_type":"stream"}]}]}