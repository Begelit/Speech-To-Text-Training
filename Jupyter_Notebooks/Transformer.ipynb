{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install datasets>=1.18.3\n!pip install transformers==4.11.3\n!pip install librosa\n!pip install jiwer","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:28:13.826389Z","iopub.execute_input":"2023-01-11T10:28:13.827028Z","iopub.status.idle":"2023-01-11T10:28:54.056315Z","shell.execute_reply.started":"2023-01-11T10:28:13.826929Z","shell.execute_reply":"2023-01-11T10:28:54.055117Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting transformers==4.11.3\n  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.11.3) (3.7.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.11.3) (1.21.6)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.11.3) (22.0)\nCollecting tokenizers<0.11,>=0.10.1\n  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.11.3) (2.28.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.11.3) (4.13.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.11.3) (2021.11.10)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.11.3) (6.0)\nRequirement already satisfied: huggingface-hub>=0.0.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.11.3) (0.10.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.11.3) (4.64.0)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==4.11.3) (0.0.53)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.0.17->transformers==4.11.3) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.11.3) (3.8.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.11.3) (1.26.13)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.11.3) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.11.3) (2022.12.7)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.11.3) (2.1.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.11.3) (1.0.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.11.3) (8.1.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.11.3) (1.15.0)\nInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.12.1\n    Uninstalling tokenizers-0.12.1:\n      Successfully uninstalled tokenizers-0.12.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.20.1\n    Uninstalling transformers-4.20.1:\n      Successfully uninstalled transformers-4.20.1\nSuccessfully installed tokenizers-0.10.3 transformers-4.11.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: librosa in /opt/conda/lib/python3.7/site-packages (0.9.2)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.0.1)\nRequirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.0.2)\nRequirement already satisfied: decorator>=4.0.10 in /opt/conda/lib/python3.7/site-packages (from librosa) (5.1.1)\nRequirement already satisfied: resampy>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.4.2)\nRequirement already satisfied: numba>=0.45.1 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.55.2)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.7.3)\nRequirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.6.0)\nRequirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.21.6)\nRequirement already satisfied: soundfile>=0.10.2 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.11.0)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.7/site-packages (from librosa) (3.0.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (22.0)\nRequirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba>=0.45.1->librosa) (0.38.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba>=0.45.1->librosa) (59.8.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from pooch>=1.0->librosa) (2.28.1)\nRequirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from pooch>=1.0->librosa) (1.4.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.19.1->librosa) (3.1.0)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.7/site-packages (from soundfile>=0.10.2->librosa) (1.15.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.13)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting jiwer\n  Downloading jiwer-2.5.1-py3-none-any.whl (15 kB)\nCollecting levenshtein==0.20.2\n  Downloading Levenshtein-0.20.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from levenshtein==0.20.2->jiwer) (2.13.7)\nInstalling collected packages: levenshtein, jiwer\n  Attempting uninstall: levenshtein\n    Found existing installation: Levenshtein 0.20.9\n    Uninstalling Levenshtein-0.20.9:\n      Successfully uninstalled Levenshtein-0.20.9\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npython-levenshtein 0.20.9 requires Levenshtein==0.20.9, but you have levenshtein 0.20.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed jiwer-2.5.1 levenshtein-0.20.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset, load_metric, Audio\nimport os\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:28:54.059412Z","iopub.execute_input":"2023-01-11T10:28:54.060429Z","iopub.status.idle":"2023-01-11T10:28:54.886098Z","shell.execute_reply.started":"2023-01-11T10:28:54.060384Z","shell.execute_reply":"2023-01-11T10:28:54.885110Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#timit = load_dataset(\"timit_asr\")\n#minds = load_dataset(\"PolyAI/minds14\",name=\"en-US\", split=\"train[:100]\")\n#minds = load_dataset(\"librispeech_asr\",'clean',split=\"train[:1000]\")#, name=\"en-US\", split=\"train\")\n#minds = load_dataset(\"common_voice\", \"tr\", split=\"train+validation\")\n#common_voice\n#librispeech_asr \n#print(timit)\nminds = load_dataset(\"superb\",\"asr\", split=\"train[:10%]\")","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:28:54.887690Z","iopub.execute_input":"2023-01-11T10:28:54.889074Z","iopub.status.idle":"2023-01-11T10:35:57.517588Z","shell.execute_reply.started":"2023-01-11T10:28:54.889003Z","shell.execute_reply":"2023-01-11T10:35:57.516205Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/7.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab6c2ea3e72447809bceb473762ddcaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/7.07k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d56f36b3c1a541bf854a0e4d079cd436"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset superb/asr (download: 6.59 GiB, generated: 12.99 MiB, post-processed: Unknown size, total: 6.60 GiB) to /root/.cache/huggingface/datasets/superb/asr/1.9.0/b8183f71eabe8c559d7f3f528ab37a6a21ad1ee088fd3423574cecad8b3ec67e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7a8b0f82b394cb984fa5088aab34ad5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/338M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53e41593ecea49769a489e1cc040fb40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/347M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edf46346bc9e41bdafaed548926ad5ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/6.39G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9a4ec9258ec4c60bc9552f2ed7bed60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"489a9d43d3aa4171843f90b8dddb0f6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/28539 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2703 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2620 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset superb downloaded and prepared to /root/.cache/huggingface/datasets/superb/asr/1.9.0/b8183f71eabe8c559d7f3f528ab37a6a21ad1ee088fd3423574cecad8b3ec67e. Subsequent calls will reuse this data.\n","output_type":"stream"}]},{"cell_type":"code","source":"minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:35:57.529793Z","iopub.execute_input":"2023-01-11T10:35:57.533440Z","iopub.status.idle":"2023-01-11T10:35:57.549528Z","shell.execute_reply.started":"2023-01-11T10:35:57.533384Z","shell.execute_reply":"2023-01-11T10:35:57.548899Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"minds","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:35:57.555749Z","iopub.execute_input":"2023-01-11T10:35:57.560247Z","iopub.status.idle":"2023-01-11T10:35:59.082553Z","shell.execute_reply.started":"2023-01-11T10:35:57.560197Z","shell.execute_reply":"2023-01-11T10:35:59.081610Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['file', 'audio', 'text', 'speaker_id', 'chapter_id', 'id'],\n    num_rows: 2854\n})"},"metadata":{}}]},{"cell_type":"code","source":"#minds[\"train\"]","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:35:59.084302Z","iopub.execute_input":"2023-01-11T10:35:59.084694Z","iopub.status.idle":"2023-01-11T10:35:59.128343Z","shell.execute_reply.started":"2023-01-11T10:35:59.084657Z","shell.execute_reply":"2023-01-11T10:35:59.126945Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#minds = minds.remove_columns(['english_transcription', 'intent_class', 'lang_id'])\nminds = minds.remove_columns(['speaker_id', 'chapter_id', 'id'])","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:35:59.130706Z","iopub.execute_input":"2023-01-11T10:35:59.131337Z","iopub.status.idle":"2023-01-11T10:35:59.171823Z","shell.execute_reply.started":"2023-01-11T10:35:59.131289Z","shell.execute_reply":"2023-01-11T10:35:59.170468Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"minds","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:35:59.174293Z","iopub.execute_input":"2023-01-11T10:35:59.174631Z","iopub.status.idle":"2023-01-11T10:35:59.232122Z","shell.execute_reply.started":"2023-01-11T10:35:59.174597Z","shell.execute_reply":"2023-01-11T10:35:59.231242Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['file', 'audio', 'text'],\n    num_rows: 2854\n})"},"metadata":{}}]},{"cell_type":"code","source":"#left_symb_list = [\"$\"]\n#for index in range(10):\n#    left_symb_list+=[str(index)]\n#left_symb_list","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:35:59.234350Z","iopub.execute_input":"2023-01-11T10:35:59.234718Z","iopub.status.idle":"2023-01-11T10:35:59.261287Z","shell.execute_reply.started":"2023-01-11T10:35:59.234682Z","shell.execute_reply":"2023-01-11T10:35:59.260322Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#for index in range(563):\n#    for symb in left_symb_list:\n#        if symb in minds[index][\"transcription\"]:\n#            print(minds[index][\"transcription\"])","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:35:59.272193Z","iopub.execute_input":"2023-01-11T10:35:59.272518Z","iopub.status.idle":"2023-01-11T10:35:59.296979Z","shell.execute_reply.started":"2023-01-11T10:35:59.272488Z","shell.execute_reply":"2023-01-11T10:35:59.294547Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import re\nchars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"]'\n\ndef remove_special_characters(batch):\n    batch[\"text\"] = re.sub(chars_to_ignore_regex, '', batch[\"text\"]).lower()\n    return batch\n\nminds = minds.map(remove_special_characters)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:36:47.254151Z","iopub.execute_input":"2023-01-11T10:36:47.254514Z","iopub.status.idle":"2023-01-11T10:36:47.586460Z","shell.execute_reply.started":"2023-01-11T10:36:47.254482Z","shell.execute_reply":"2023-01-11T10:36:47.585329Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2854 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92f7ddb69a3a4cac8736748be6cea30d"}},"metadata":{}}]},{"cell_type":"code","source":"minds","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:36:51.439250Z","iopub.execute_input":"2023-01-11T10:36:51.439651Z","iopub.status.idle":"2023-01-11T10:36:51.445499Z","shell.execute_reply.started":"2023-01-11T10:36:51.439616Z","shell.execute_reply":"2023-01-11T10:36:51.444626Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['file', 'audio', 'text'],\n    num_rows: 2854\n})"},"metadata":{}}]},{"cell_type":"code","source":"minds = minds.train_test_split(test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:36:51.725000Z","iopub.execute_input":"2023-01-11T10:36:51.725356Z","iopub.status.idle":"2023-01-11T10:36:51.758844Z","shell.execute_reply.started":"2023-01-11T10:36:51.725325Z","shell.execute_reply":"2023-01-11T10:36:51.757815Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"minds[\"train\"][0]\n#minds[0]","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:36:52.035729Z","iopub.execute_input":"2023-01-11T10:36:52.036082Z","iopub.status.idle":"2023-01-11T10:36:55.290185Z","shell.execute_reply.started":"2023-01-11T10:36:52.036052Z","shell.execute_reply":"2023-01-11T10:36:55.288832Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'file': '/root/.cache/huggingface/datasets/downloads/extracted/39bad2659671b430f631158d09f2c89e593891e6d95eed4dbdda430301560fc0/LibriSpeech/train-clean-100/1594/135914/1594-135914-0096.flac',\n 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/39bad2659671b430f631158d09f2c89e593891e6d95eed4dbdda430301560fc0/LibriSpeech/train-clean-100/1594/135914/1594-135914-0096.flac',\n  'array': array([-0.00134277, -0.0017395 , -0.00067139, ...,  0.00106812,\n          0.00106812,  0.00100708], dtype=float32),\n  'sampling_rate': 16000},\n 'text': 'who told her that ganem had rested well that night and that his disorder proceeding altogether from melancholy the cause being removed he would soon recover his health'}"},"metadata":{}}]},{"cell_type":"code","source":"def extract_all_chars(batch):\n    all_text = \" \".join(batch[\"text\"])\n    vocab = list(set(all_text))\n    return {\"vocab\": [vocab], \"all_text\": [all_text]}\nvocabs = minds.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=minds.column_names[\"train\"])","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:36:55.293275Z","iopub.execute_input":"2023-01-11T10:36:55.293820Z","iopub.status.idle":"2023-01-11T10:36:55.461234Z","shell.execute_reply.started":"2023-01-11T10:36:55.293770Z","shell.execute_reply":"2023-01-11T10:36:55.460086Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33fde8e3f52b49dda10e794d5178a278"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06979610021145d78685d5d637d05203"}},"metadata":{}}]},{"cell_type":"code","source":"vocab_list = list(set(vocabs[\"train\"][\"vocab\"][0]) | set(vocabs[\"test\"][\"vocab\"][0]))\nvocab_dict = {v: k for k, v in enumerate(vocab_list)}\nvocab_dict","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:36:55.463154Z","iopub.execute_input":"2023-01-11T10:36:55.463813Z","iopub.status.idle":"2023-01-11T10:36:55.475957Z","shell.execute_reply.started":"2023-01-11T10:36:55.463763Z","shell.execute_reply":"2023-01-11T10:36:55.474628Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'m': 0,\n 'c': 1,\n 'p': 2,\n 'y': 3,\n 'h': 4,\n 'r': 5,\n 'a': 6,\n \"'\": 7,\n 't': 8,\n 'u': 9,\n 'l': 10,\n ' ': 11,\n 'b': 12,\n 'x': 13,\n 'g': 14,\n 'j': 15,\n 's': 16,\n 'q': 17,\n 'o': 18,\n 'v': 19,\n 'i': 20,\n 'e': 21,\n 'd': 22,\n 'z': 23,\n 'n': 24,\n 'w': 25,\n 'k': 26,\n 'f': 27}"},"metadata":{}}]},{"cell_type":"code","source":"len(vocab_dict)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:36:55.479580Z","iopub.execute_input":"2023-01-11T10:36:55.480425Z","iopub.status.idle":"2023-01-11T10:36:55.487539Z","shell.execute_reply.started":"2023-01-11T10:36:55.480390Z","shell.execute_reply":"2023-01-11T10:36:55.486384Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"28"},"metadata":{}}]},{"cell_type":"code","source":"vocab_dict[\"|\"] = vocab_dict[\" \"]\ndel vocab_dict[\" \"]\nvocab_dict[\"[UNK]\"] = len(vocab_dict)\nvocab_dict[\"[PAD]\"] = len(vocab_dict)\nprint(len(vocab_dict))","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:36:55.489357Z","iopub.execute_input":"2023-01-11T10:36:55.489933Z","iopub.status.idle":"2023-01-11T10:36:55.498083Z","shell.execute_reply.started":"2023-01-11T10:36:55.489904Z","shell.execute_reply":"2023-01-11T10:36:55.496828Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"30\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nwith open('./vocab.json', 'w') as vocab_file:\n    json.dump(vocab_dict, vocab_file)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:36:55.500219Z","iopub.execute_input":"2023-01-11T10:36:55.500647Z","iopub.status.idle":"2023-01-11T10:36:55.508481Z","shell.execute_reply.started":"2023-01-11T10:36:55.500609Z","shell.execute_reply":"2023-01-11T10:36:55.507256Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from transformers import Wav2Vec2CTCTokenizer\n\ntokenizer = Wav2Vec2CTCTokenizer(\"./vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")\n","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:36:55.510646Z","iopub.execute_input":"2023-01-11T10:36:55.511240Z","iopub.status.idle":"2023-01-11T10:37:03.669906Z","shell.execute_reply.started":"2023-01-11T10:36:55.511205Z","shell.execute_reply":"2023-01-11T10:37:03.668586Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"tokenizer","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:37:03.671518Z","iopub.execute_input":"2023-01-11T10:37:03.671972Z","iopub.status.idle":"2023-01-11T10:37:03.684200Z","shell.execute_reply.started":"2023-01-11T10:37:03.671933Z","shell.execute_reply":"2023-01-11T10:37:03.681560Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"PreTrainedTokenizer(name_or_path='', vocab_size=30, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '[UNK]', 'pad_token': '[PAD]'})"},"metadata":{}}]},{"cell_type":"code","source":"os.mkdir(\"./tokenizer_dir\")","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:37:03.690197Z","iopub.execute_input":"2023-01-11T10:37:03.691165Z","iopub.status.idle":"2023-01-11T10:37:03.698151Z","shell.execute_reply.started":"2023-01-11T10:37:03.691121Z","shell.execute_reply":"2023-01-11T10:37:03.696808Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"tokenizer.save_pretrained(\"./tokenizer_dir\")","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:37:03.700239Z","iopub.execute_input":"2023-01-11T10:37:03.700699Z","iopub.status.idle":"2023-01-11T10:37:03.709864Z","shell.execute_reply.started":"2023-01-11T10:37:03.700663Z","shell.execute_reply":"2023-01-11T10:37:03.708496Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"('./tokenizer_dir/tokenizer_config.json',\n './tokenizer_dir/special_tokens_map.json',\n './tokenizer_dir/vocab.json',\n './tokenizer_dir/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import Wav2Vec2FeatureExtractor\n\nfeature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:37:03.711280Z","iopub.execute_input":"2023-01-11T10:37:03.712834Z","iopub.status.idle":"2023-01-11T10:37:03.721175Z","shell.execute_reply.started":"2023-01-11T10:37:03.712796Z","shell.execute_reply":"2023-01-11T10:37:03.720227Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from transformers import Wav2Vec2Processor\n\nprocessor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:37:03.722890Z","iopub.execute_input":"2023-01-11T10:37:03.723565Z","iopub.status.idle":"2023-01-11T10:37:03.732464Z","shell.execute_reply.started":"2023-01-11T10:37:03.723528Z","shell.execute_reply":"2023-01-11T10:37:03.731519Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"#minds[\"train\"][0][\"path\"]","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:37:03.733949Z","iopub.execute_input":"2023-01-11T10:37:03.734460Z","iopub.status.idle":"2023-01-11T10:37:03.740967Z","shell.execute_reply.started":"2023-01-11T10:37:03.734425Z","shell.execute_reply":"2023-01-11T10:37:03.739894Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#minds[\"train\"][0][\"audio\"]","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:37:03.742262Z","iopub.execute_input":"2023-01-11T10:37:03.743425Z","iopub.status.idle":"2023-01-11T10:37:03.749495Z","shell.execute_reply.started":"2023-01-11T10:37:03.743377Z","shell.execute_reply":"2023-01-11T10:37:03.748404Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset(batch):\n    audio = batch[\"audio\"]\n\n    # batched output is \"un-batched\" to ensure mapping is correct\n    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n    \n    with processor.as_target_processor():\n        batch[\"labels\"] = processor(batch[\"text\"]).input_ids\n    return batch\n","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:37:03.751127Z","iopub.execute_input":"2023-01-11T10:37:03.751997Z","iopub.status.idle":"2023-01-11T10:37:03.758956Z","shell.execute_reply.started":"2023-01-11T10:37:03.751961Z","shell.execute_reply":"2023-01-11T10:37:03.758020Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"minds = minds.map(prepare_dataset, remove_columns=minds.column_names[\"train\"], num_proc=4)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:37:03.760502Z","iopub.execute_input":"2023-01-11T10:37:03.761365Z","iopub.status.idle":"2023-01-11T10:37:44.220978Z","shell.execute_reply.started":"2023-01-11T10:37:03.761210Z","shell.execute_reply":"2023-01-11T10:37:44.219658Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"        ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/571 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"846ba36de18e49c5b14429f378438d04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/571 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"558bf3168219423eaf02edf414dd1ca7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/571 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db437545b50c4ff7a6711a04df4f77bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/570 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a78a11a11dc048349d5e7e7591b3ffdd"}},"metadata":{}},{"name":"stdout","text":"        ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/143 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a76b69525a5e441589a9eddbe73c9136"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/143 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afc23533e6f346fdb02e30121c524556"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/143 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46aaabc1618b4aeb8908fe464584cff7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/142 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bebaae9c7954654bfb29d84d5e39043"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass, field\nfrom typing import Any, Dict, List, Optional, Union\n\n@dataclass\nclass DataCollatorCTCWithPadding:\n    \"\"\"\n    Data collator that will dynamically pad the inputs received.\n    Args:\n        processor (:class:`~transformers.Wav2Vec2Processor`)\n            The processor used for proccessing the data.\n        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n            among:\n            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n              sequence if provided).\n            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n              maximum acceptable input length for the model if that argument is not provided.\n            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n              different lengths).\n        max_length (:obj:`int`, `optional`):\n            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n        max_length_labels (:obj:`int`, `optional`):\n            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n        pad_to_multiple_of (:obj:`int`, `optional`):\n            If set will pad the sequence to a multiple of the provided value.\n            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n            7.5 (Volta).\n    \"\"\"\n\n    processor: Wav2Vec2Processor\n    padding: Union[bool, str] = True\n    max_length: Optional[int] = None\n    max_length_labels: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    pad_to_multiple_of_labels: Optional[int] = None\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lengths and need\n        # different padding methods\n        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n\n        batch = self.processor.pad(\n            input_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors=\"pt\",\n        )\n        with self.processor.as_target_processor():\n            labels_batch = self.processor.pad(\n                label_features,\n                padding=self.padding,\n                max_length=self.max_length_labels,\n                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n                return_tensors=\"pt\",\n            )\n\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        batch[\"labels\"] = labels\n\n        return batch\n","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:37:44.223226Z","iopub.execute_input":"2023-01-11T10:37:44.223981Z","iopub.status.idle":"2023-01-11T10:37:44.237973Z","shell.execute_reply.started":"2023-01-11T10:37:44.223935Z","shell.execute_reply":"2023-01-11T10:37:44.236631Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:37:44.242161Z","iopub.execute_input":"2023-01-11T10:37:44.242533Z","iopub.status.idle":"2023-01-11T10:37:45.921820Z","shell.execute_reply.started":"2023-01-11T10:37:44.242492Z","shell.execute_reply":"2023-01-11T10:37:45.920595Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"wer_metric = load_metric(\"wer\")\n","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:37:45.923519Z","iopub.execute_input":"2023-01-11T10:37:45.924477Z","iopub.status.idle":"2023-01-11T10:37:46.719165Z","shell.execute_reply.started":"2023-01-11T10:37:45.924433Z","shell.execute_reply":"2023-01-11T10:37:46.718235Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.90k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8ff3575548a4e69b6b260418ba10b09"}},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\ndef compute_metrics(pred):\n    pred_logits = pred.predictions\n    pred_ids = np.argmax(pred_logits, axis=-1)\n\n    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n\n    pred_str = processor.batch_decode(pred_ids)\n    # we do not want to group tokens when computing the metrics\n    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n\n    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n    #print({\"wer\": wer})\n    return {\"wer\": wer}\n","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:37:46.724415Z","iopub.execute_input":"2023-01-11T10:37:46.724791Z","iopub.status.idle":"2023-01-11T10:37:46.731202Z","shell.execute_reply.started":"2023-01-11T10:37:46.724761Z","shell.execute_reply":"2023-01-11T10:37:46.730108Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"from transformers import Wav2Vec2ForCTC\n\nmodel = Wav2Vec2ForCTC.from_pretrained(\n    \"facebook/wav2vec2-base\", \n    ctc_loss_reduction=\"mean\", \n    pad_token_id=processor.tokenizer.pad_token_id,\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:37:46.732705Z","iopub.execute_input":"2023-01-11T10:37:46.733391Z","iopub.status.idle":"2023-01-11T10:38:06.031935Z","shell.execute_reply.started":"2023-01-11T10:37:46.733350Z","shell.execute_reply":"2023-01-11T10:38:06.030595Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.80k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85b059be71744b9d9be77c6d747fca1b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/363M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7673f181ca84214860c7da727339661"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForCTC: ['quantizer.weight_proj.bias', 'project_q.bias', 'quantizer.codevectors', 'project_q.weight', 'project_hid.bias', 'project_hid.weight', 'quantizer.weight_proj.weight']\n- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['lm_head.weight', 'lm_head.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.freeze_feature_extractor()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:38:06.033638Z","iopub.execute_input":"2023-01-11T10:38:06.034280Z","iopub.status.idle":"2023-01-11T10:38:06.040199Z","shell.execute_reply.started":"2023-01-11T10:38:06.034233Z","shell.execute_reply":"2023-01-11T10:38:06.038922Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"os.mkdir(\"./model\")","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:38:06.041856Z","iopub.execute_input":"2023-01-11T10:38:06.043032Z","iopub.status.idle":"2023-01-11T10:38:06.051615Z","shell.execute_reply.started":"2023-01-11T10:38:06.042991Z","shell.execute_reply":"2023-01-11T10:38:06.050135Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n  output_dir=\"./model\",\n  group_by_length=True,\n  per_device_train_batch_size=8,\n  evaluation_strategy=\"steps\",\n  num_train_epochs=30,\n  fp16=True,\n  gradient_checkpointing=True, \n  save_steps=500,\n  eval_steps=50,\n  logging_steps=50,\n  learning_rate=1e-4,\n  weight_decay=0.005,\n  warmup_steps=1000,\n  save_total_limit=2,\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:38:06.053359Z","iopub.execute_input":"2023-01-11T10:38:06.054765Z","iopub.status.idle":"2023-01-11T10:38:06.242988Z","shell.execute_reply.started":"2023-01-11T10:38:06.054721Z","shell.execute_reply":"2023-01-11T10:38:06.241992Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"\n\nfrom transformers import Trainer, TrainerCallback\n\n#class PrinterCallback(TrainerCallback):\n#    def on_log(self, args, state, control, logs=None, **kwargs):\n#        _ = logs.pop(\"total_flos\", None)\n#        if state.is_local_process_zero:\n#            print(logs)\n\ntrainer = Trainer(\n    model=model,\n    data_collator=data_collator,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=minds[\"train\"],\n    eval_dataset=minds[\"test\"],\n    tokenizer=processor.feature_extractor,\n    #callbacks=[PrinterCallback]\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:38:06.315773Z","iopub.execute_input":"2023-01-11T10:38:06.316434Z","iopub.status.idle":"2023-01-11T10:38:12.497320Z","shell.execute_reply.started":"2023-01-11T10:38:06.316385Z","shell.execute_reply":"2023-01-11T10:38:12.496228Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"Using amp fp16 backend\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T10:38:12.499752Z","iopub.execute_input":"2023-01-11T10:38:12.500508Z","iopub.status.idle":"2023-01-11T17:16:31.997799Z","shell.execute_reply.started":"2023-01-11T10:38:12.500464Z","shell.execute_reply":"2023-01-11T17:16:31.996879Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"***** Running training *****\n  Num examples = 2283\n  Num Epochs = 30\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 16\n  Gradient Accumulation steps = 1\n  Total optimization steps = 4290\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.8 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230111_104104-229gugua</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/kevin_dima/huggingface/runs/229gugua\" target=\"_blank\">./model</a></strong> to <a href=\"https://wandb.ai/kevin_dima/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/feature_extraction_utils.py:158: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:207.)\n  tensor = as_tensor(value)\n/opt/conda/lib/python3.7/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:882: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n  return (input_length - kernel_size) // stride + 1\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4290' max='4290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4290/4290 6:34:57, Epoch 30/30]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Wer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>8.970800</td>\n      <td>12.933688</td>\n      <td>0.996682</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>4.812500</td>\n      <td>3.458613</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>3.054000</td>\n      <td>3.190386</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>2.952400</td>\n      <td>3.040305</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>2.920800</td>\n      <td>2.989865</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>2.896000</td>\n      <td>2.950098</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>2.880500</td>\n      <td>2.937628</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>2.880200</td>\n      <td>2.936162</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>2.866500</td>\n      <td>2.946703</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>2.718500</td>\n      <td>2.392516</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.715600</td>\n      <td>1.133375</td>\n      <td>0.720593</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.915000</td>\n      <td>0.645254</td>\n      <td>0.469924</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.586500</td>\n      <td>0.463401</td>\n      <td>0.367762</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.447500</td>\n      <td>0.350664</td>\n      <td>0.299315</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.356600</td>\n      <td>0.312337</td>\n      <td>0.269185</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.286500</td>\n      <td>0.264326</td>\n      <td>0.233062</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.258900</td>\n      <td>0.240427</td>\n      <td>0.214278</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.218300</td>\n      <td>0.223626</td>\n      <td>0.200792</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.185400</td>\n      <td>0.210705</td>\n      <td>0.182061</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.185900</td>\n      <td>0.205939</td>\n      <td>0.179493</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.151300</td>\n      <td>0.194385</td>\n      <td>0.163170</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.137900</td>\n      <td>0.180455</td>\n      <td>0.150862</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.134800</td>\n      <td>0.170756</td>\n      <td>0.145992</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.110600</td>\n      <td>0.167057</td>\n      <td>0.139891</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.116900</td>\n      <td>0.179715</td>\n      <td>0.143690</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.105700</td>\n      <td>0.165560</td>\n      <td>0.142727</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>0.092400</td>\n      <td>0.162200</td>\n      <td>0.130793</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.092400</td>\n      <td>0.159516</td>\n      <td>0.131756</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>0.083100</td>\n      <td>0.155045</td>\n      <td>0.129241</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.079200</td>\n      <td>0.162143</td>\n      <td>0.132827</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>0.075300</td>\n      <td>0.152278</td>\n      <td>0.127422</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.070500</td>\n      <td>0.161055</td>\n      <td>0.123997</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>0.069800</td>\n      <td>0.158413</td>\n      <td>0.125709</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.066400</td>\n      <td>0.233682</td>\n      <td>0.137483</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>0.061000</td>\n      <td>0.201644</td>\n      <td>0.127743</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.057800</td>\n      <td>0.149081</td>\n      <td>0.121695</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>0.058400</td>\n      <td>0.151035</td>\n      <td>0.118270</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.057100</td>\n      <td>0.157250</td>\n      <td>0.119662</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>0.054900</td>\n      <td>0.160974</td>\n      <td>0.118431</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.052800</td>\n      <td>0.160672</td>\n      <td>0.117468</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>0.051300</td>\n      <td>0.161114</td>\n      <td>0.117682</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.048700</td>\n      <td>0.152870</td>\n      <td>0.115380</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>0.047100</td>\n      <td>0.154769</td>\n      <td>0.116611</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.042700</td>\n      <td>0.150214</td>\n      <td>0.113775</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>0.045000</td>\n      <td>0.160753</td>\n      <td>0.115434</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.046100</td>\n      <td>0.454145</td>\n      <td>0.130204</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>0.039100</td>\n      <td>0.289500</td>\n      <td>0.119394</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.041700</td>\n      <td>0.206992</td>\n      <td>0.117468</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>0.039900</td>\n      <td>0.216734</td>\n      <td>0.117789</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.039100</td>\n      <td>0.229817</td>\n      <td>0.120250</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>0.038700</td>\n      <td>0.243955</td>\n      <td>0.114471</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.041200</td>\n      <td>0.157907</td>\n      <td>0.107514</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>0.037800</td>\n      <td>0.165110</td>\n      <td>0.111367</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>0.035900</td>\n      <td>0.163275</td>\n      <td>0.107460</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>0.038400</td>\n      <td>0.157685</td>\n      <td>0.108852</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.032200</td>\n      <td>0.159317</td>\n      <td>0.107674</td>\n    </tr>\n    <tr>\n      <td>2850</td>\n      <td>0.032400</td>\n      <td>0.156892</td>\n      <td>0.105855</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>0.038400</td>\n      <td>0.158408</td>\n      <td>0.106657</td>\n    </tr>\n    <tr>\n      <td>2950</td>\n      <td>0.032500</td>\n      <td>0.158991</td>\n      <td>0.105480</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.028900</td>\n      <td>0.163045</td>\n      <td>0.103232</td>\n    </tr>\n    <tr>\n      <td>3050</td>\n      <td>0.031500</td>\n      <td>0.161408</td>\n      <td>0.105908</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>0.033900</td>\n      <td>0.164287</td>\n      <td>0.104463</td>\n    </tr>\n    <tr>\n      <td>3150</td>\n      <td>0.028800</td>\n      <td>0.168220</td>\n      <td>0.105855</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.026000</td>\n      <td>0.157064</td>\n      <td>0.102001</td>\n    </tr>\n    <tr>\n      <td>3250</td>\n      <td>0.030000</td>\n      <td>0.158201</td>\n      <td>0.102323</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>0.028900</td>\n      <td>0.163157</td>\n      <td>0.102697</td>\n    </tr>\n    <tr>\n      <td>3350</td>\n      <td>0.027300</td>\n      <td>0.163219</td>\n      <td>0.102590</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>0.025300</td>\n      <td>0.169892</td>\n      <td>0.103768</td>\n    </tr>\n    <tr>\n      <td>3450</td>\n      <td>0.025700</td>\n      <td>0.160977</td>\n      <td>0.102751</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.023500</td>\n      <td>0.161067</td>\n      <td>0.101894</td>\n    </tr>\n    <tr>\n      <td>3550</td>\n      <td>0.026700</td>\n      <td>0.157918</td>\n      <td>0.101145</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>0.021300</td>\n      <td>0.162430</td>\n      <td>0.100717</td>\n    </tr>\n    <tr>\n      <td>3650</td>\n      <td>0.023700</td>\n      <td>0.157789</td>\n      <td>0.100878</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>0.024300</td>\n      <td>0.156730</td>\n      <td>0.100396</td>\n    </tr>\n    <tr>\n      <td>3750</td>\n      <td>0.022100</td>\n      <td>0.162191</td>\n      <td>0.100396</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>0.022200</td>\n      <td>0.164648</td>\n      <td>0.100128</td>\n    </tr>\n    <tr>\n      <td>3850</td>\n      <td>0.026000</td>\n      <td>0.158186</td>\n      <td>0.101145</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>0.022100</td>\n      <td>0.159907</td>\n      <td>0.099379</td>\n    </tr>\n    <tr>\n      <td>3950</td>\n      <td>0.022200</td>\n      <td>0.158786</td>\n      <td>0.100610</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.021500</td>\n      <td>0.158510</td>\n      <td>0.099700</td>\n    </tr>\n    <tr>\n      <td>4050</td>\n      <td>0.021500</td>\n      <td>0.161225</td>\n      <td>0.099593</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>0.021900</td>\n      <td>0.162327</td>\n      <td>0.099754</td>\n    </tr>\n    <tr>\n      <td>4150</td>\n      <td>0.020500</td>\n      <td>0.162155</td>\n      <td>0.099433</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>0.021500</td>\n      <td>0.163012</td>\n      <td>0.099914</td>\n    </tr>\n    <tr>\n      <td>4250</td>\n      <td>0.020100</td>\n      <td>0.162898</td>\n      <td>0.098951</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\nSaving model checkpoint to ./model/checkpoint-500\nConfiguration saved in ./model/checkpoint-500/config.json\nModel weights saved in ./model/checkpoint-500/pytorch_model.bin\nConfiguration saved in ./model/checkpoint-500/preprocessor_config.json\n/opt/conda/lib/python3.7/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:882: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n  return (input_length - kernel_size) // stride + 1\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\nSaving model checkpoint to ./model/checkpoint-1000\nConfiguration saved in ./model/checkpoint-1000/config.json\nModel weights saved in ./model/checkpoint-1000/pytorch_model.bin\nConfiguration saved in ./model/checkpoint-1000/preprocessor_config.json\n/opt/conda/lib/python3.7/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:882: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n  return (input_length - kernel_size) // stride + 1\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\nSaving model checkpoint to ./model/checkpoint-1500\nConfiguration saved in ./model/checkpoint-1500/config.json\nModel weights saved in ./model/checkpoint-1500/pytorch_model.bin\nConfiguration saved in ./model/checkpoint-1500/preprocessor_config.json\nDeleting older checkpoint [model/checkpoint-500] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:882: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n  return (input_length - kernel_size) // stride + 1\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\nSaving model checkpoint to ./model/checkpoint-2000\nConfiguration saved in ./model/checkpoint-2000/config.json\nModel weights saved in ./model/checkpoint-2000/pytorch_model.bin\nConfiguration saved in ./model/checkpoint-2000/preprocessor_config.json\nDeleting older checkpoint [model/checkpoint-1000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:882: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n  return (input_length - kernel_size) // stride + 1\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\nSaving model checkpoint to ./model/checkpoint-2500\nConfiguration saved in ./model/checkpoint-2500/config.json\nModel weights saved in ./model/checkpoint-2500/pytorch_model.bin\nConfiguration saved in ./model/checkpoint-2500/preprocessor_config.json\nDeleting older checkpoint [model/checkpoint-1500] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:882: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n  return (input_length - kernel_size) // stride + 1\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\nSaving model checkpoint to ./model/checkpoint-3000\nConfiguration saved in ./model/checkpoint-3000/config.json\nModel weights saved in ./model/checkpoint-3000/pytorch_model.bin\nConfiguration saved in ./model/checkpoint-3000/preprocessor_config.json\nDeleting older checkpoint [model/checkpoint-2000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:882: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n  return (input_length - kernel_size) // stride + 1\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\nSaving model checkpoint to ./model/checkpoint-3500\nConfiguration saved in ./model/checkpoint-3500/config.json\nModel weights saved in ./model/checkpoint-3500/pytorch_model.bin\nConfiguration saved in ./model/checkpoint-3500/preprocessor_config.json\nDeleting older checkpoint [model/checkpoint-2500] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:882: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n  return (input_length - kernel_size) // stride + 1\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\nSaving model checkpoint to ./model/checkpoint-4000\nConfiguration saved in ./model/checkpoint-4000/config.json\nModel weights saved in ./model/checkpoint-4000/pytorch_model.bin\nConfiguration saved in ./model/checkpoint-4000/preprocessor_config.json\nDeleting older checkpoint [model/checkpoint-3000] due to args.save_total_limit\n/opt/conda/lib/python3.7/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:882: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n  return (input_length - kernel_size) // stride + 1\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n***** Running Evaluation *****\n  Num examples = 571\n  Batch size = 16\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4290, training_loss=0.5276449651012332, metrics={'train_runtime': 23746.0914, 'train_samples_per_second': 2.884, 'train_steps_per_second': 0.181, 'total_flos': 7.822566458000963e+18, 'train_loss': 0.5276449651012332, 'epoch': 30.0})"},"metadata":{}}]},{"cell_type":"code","source":"import shutil\nshutil.make_archive(output_filename, 'zip', dir_name)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.save_model(\"./\")","metadata":{"execution":{"iopub.status.busy":"2023-01-11T17:17:32.993168Z","iopub.execute_input":"2023-01-11T17:17:32.993890Z","iopub.status.idle":"2023-01-11T17:17:33.833426Z","shell.execute_reply.started":"2023-01-11T17:17:32.993853Z","shell.execute_reply":"2023-01-11T17:17:33.832507Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"Saving model checkpoint to ./\nConfiguration saved in ./config.json\nModel weights saved in ./pytorch_model.bin\nConfiguration saved in ./preprocessor_config.json\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip model.zip ./model","metadata":{"execution":{"iopub.status.busy":"2023-01-11T17:20:32.482563Z","iopub.execute_input":"2023-01-11T17:20:32.482994Z","iopub.status.idle":"2023-01-11T17:20:33.613522Z","shell.execute_reply.started":"2023-01-11T17:20:32.482960Z","shell.execute_reply":"2023-01-11T17:20:33.612431Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"updating: model/ (stored 0%)\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip py_model.zip /kaggle/working/pytorch_model.bin","metadata":{"execution":{"iopub.status.busy":"2023-01-11T17:26:27.397498Z","iopub.execute_input":"2023-01-11T17:26:27.398355Z","iopub.status.idle":"2023-01-11T17:26:27.407947Z","shell.execute_reply.started":"2023-01-11T17:26:27.398316Z","shell.execute_reply":"2023-01-11T17:26:27.406181Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"UsageError: Line magic function `%zip` not found.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2023-01-11T17:35:50.476517Z","iopub.execute_input":"2023-01-11T17:35:50.476930Z","iopub.status.idle":"2023-01-11T17:35:50.488415Z","shell.execute_reply.started":"2023-01-11T17:35:50.476898Z","shell.execute_reply":"2023-01-11T17:35:50.487027Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'py_model.zip')","metadata":{"execution":{"iopub.status.busy":"2023-01-11T17:27:57.842059Z","iopub.execute_input":"2023-01-11T17:27:57.842513Z","iopub.status.idle":"2023-01-11T17:27:57.854525Z","shell.execute_reply.started":"2023-01-11T17:27:57.842477Z","shell.execute_reply":"2023-01-11T17:27:57.853654Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/py_model.zip","text/html":"<a href='py_model.zip' target='_blank'>py_model.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"%ls","metadata":{"execution":{"iopub.status.busy":"2023-01-11T17:35:54.811897Z","iopub.execute_input":"2023-01-11T17:35:54.812321Z","iopub.status.idle":"2023-01-11T17:35:55.963213Z","shell.execute_reply.started":"2023-01-11T17:35:54.812286Z","shell.execute_reply":"2023-01-11T17:35:55.962094Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"__notebook_source__.ipynb  preprocessor_config.json  training_args.bin\nconfig.json                py_model.zip              vocab.json\n\u001b[0m\u001b[01;34mmodel\u001b[0m/                     pytorch_model.bin         \u001b[01;34mwandb\u001b[0m/\nmodel.zip                  \u001b[01;34mtokenizer_dir\u001b[0m/\n","output_type":"stream"}]},{"cell_type":"code","source":"!tar -czvf my_work.zip -C . .","metadata":{"execution":{"iopub.status.busy":"2023-01-11T17:36:06.200291Z","iopub.execute_input":"2023-01-11T17:36:06.200722Z","iopub.status.idle":"2023-01-11T17:39:04.590464Z","shell.execute_reply.started":"2023-01-11T17:36:06.200686Z","shell.execute_reply":"2023-01-11T17:39:04.589136Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"./\n./vocab.json\n./pytorch_model.bin\n./.virtual_documents/\n./my_work.zip\ntar: ./my_work.zip: file changed as we read it\n./config.json\n./model/\n./model/runs/\n./model/runs/Jan11_10-38-06_04969468206b/\n./model/runs/Jan11_10-38-06_04969468206b/events.out.tfevents.1673433645.04969468206b.23.0\n./model/runs/Jan11_10-38-06_04969468206b/1673433645.9175594/\n./model/runs/Jan11_10-38-06_04969468206b/1673433645.9175594/events.out.tfevents.1673433645.04969468206b.23.1\n./model/checkpoint-4000/\n./model/checkpoint-4000/trainer_state.json\n./model/checkpoint-4000/pytorch_model.bin\n./model/checkpoint-4000/scaler.pt\n./model/checkpoint-4000/config.json\n./model/checkpoint-4000/scheduler.pt\n./model/checkpoint-4000/optimizer.pt\n./model/checkpoint-4000/rng_state.pth\n./model/checkpoint-4000/training_args.bin\n./model/checkpoint-4000/preprocessor_config.json\n./model/checkpoint-3500/\n./model/checkpoint-3500/trainer_state.json\n./model/checkpoint-3500/pytorch_model.bin\n./model/checkpoint-3500/scaler.pt\n./model/checkpoint-3500/config.json\n./model/checkpoint-3500/scheduler.pt\n./model/checkpoint-3500/optimizer.pt\n./model/checkpoint-3500/rng_state.pth\n./model/checkpoint-3500/training_args.bin\n./model/checkpoint-3500/preprocessor_config.json\n./wandb/\n./wandb/run-20230111_104104-229gugua/\n./wandb/run-20230111_104104-229gugua/run-229gugua.wandb\n./wandb/run-20230111_104104-229gugua/tmp/\n./wandb/run-20230111_104104-229gugua/tmp/code/\n./wandb/run-20230111_104104-229gugua/files/\n./wandb/run-20230111_104104-229gugua/files/requirements.txt\n./wandb/run-20230111_104104-229gugua/files/output.log\n./wandb/run-20230111_104104-229gugua/files/config.yaml\n./wandb/run-20230111_104104-229gugua/files/conda-environment.yaml\n./wandb/run-20230111_104104-229gugua/files/wandb-metadata.json\n./wandb/run-20230111_104104-229gugua/files/wandb-summary.json\n./wandb/run-20230111_104104-229gugua/logs/\n./wandb/run-20230111_104104-229gugua/logs/debug-internal.log\ntar: ./wandb/run-20230111_104104-229gugua/logs/debug-internal.log: file changed as we read it\n./wandb/run-20230111_104104-229gugua/logs/debug.log\n./wandb/debug-internal.log\n./wandb/debug.log\n./wandb/latest-run\n./model.zip\n./py_model.zip\n./tokenizer_dir/\n./tokenizer_dir/vocab.json\n./tokenizer_dir/tokenizer_config.json\n./tokenizer_dir/special_tokens_map.json\n./__notebook_source__.ipynb\n./training_args.bin\n./preprocessor_config.json\ntar: .: file changed as we read it\n","output_type":"stream"}]},{"cell_type":"code","source":"FileLink(r'my_work.zip')","metadata":{"execution":{"iopub.status.busy":"2023-01-11T17:39:48.034881Z","iopub.execute_input":"2023-01-11T17:39:48.036281Z","iopub.status.idle":"2023-01-11T17:39:48.046824Z","shell.execute_reply.started":"2023-01-11T17:39:48.036239Z","shell.execute_reply":"2023-01-11T17:39:48.045801Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/my_work.zip","text/html":"<a href='my_work.zip' target='_blank'>my_work.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"import shutil\nshutil.make_archive(\"tok\", 'zip', \"./tokenizer_dir\")","metadata":{"execution":{"iopub.status.busy":"2023-01-11T17:52:28.432346Z","iopub.execute_input":"2023-01-11T17:52:28.432747Z","iopub.status.idle":"2023-01-11T17:52:28.444976Z","shell.execute_reply.started":"2023-01-11T17:52:28.432713Z","shell.execute_reply":"2023-01-11T17:52:28.443676Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/tok.zip'"},"metadata":{}}]},{"cell_type":"code","source":"!cd /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2023-01-11T17:53:26.220874Z","iopub.execute_input":"2023-01-11T17:53:26.221322Z","iopub.status.idle":"2023-01-11T17:53:27.451973Z","shell.execute_reply.started":"2023-01-11T17:53:26.221283Z","shell.execute_reply":"2023-01-11T17:53:27.450627Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"!zip -r file.zip /kaggle/working/tokenizer_dir","metadata":{"execution":{"iopub.status.busy":"2023-01-11T17:54:27.202000Z","iopub.execute_input":"2023-01-11T17:54:27.202409Z","iopub.status.idle":"2023-01-11T17:54:28.345452Z","shell.execute_reply.started":"2023-01-11T17:54:27.202375Z","shell.execute_reply":"2023-01-11T17:54:28.344120Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/tokenizer_dir/ (stored 0%)\n  adding: kaggle/working/tokenizer_dir/vocab.json (deflated 49%)\n  adding: kaggle/working/tokenizer_dir/tokenizer_config.json (deflated 34%)\n  adding: kaggle/working/tokenizer_dir/special_tokens_map.json (deflated 39%)\n","output_type":"stream"}]},{"cell_type":"code","source":"FileLink(r'file.zip')","metadata":{"execution":{"iopub.status.busy":"2023-01-11T18:17:59.390243Z","iopub.execute_input":"2023-01-11T18:17:59.390709Z","iopub.status.idle":"2023-01-11T18:17:59.399708Z","shell.execute_reply.started":"2023-01-11T18:17:59.390670Z","shell.execute_reply":"2023-01-11T18:17:59.398698Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/file.zip","text/html":"<a href='file.zip' target='_blank'>file.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"from IPython.display import FileLink\n","metadata":{},"execution_count":null,"outputs":[]}]}